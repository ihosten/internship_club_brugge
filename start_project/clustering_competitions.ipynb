{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3571fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars.selectors as cs\n",
    "import polars as pl\n",
    "import plotly as plt\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import tukey_hsd\n",
    "from tqdm import tqdm\n",
    "import xlsxwriter\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import statistics\n",
    "import os\n",
    "from sklearn.cluster import KMeans  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "import matplotlib.pyplot as plt                                          \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "import altair as alt\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from kneed import KneeLocator\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c56052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_path = \"./parquet4visual.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47303fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the required columns\n",
    "df = pl.read_parquet(parquet_path,\n",
    "   columns = [\n",
    "      'competition_region_division', \n",
    "      'position_grouped', \n",
    "      'PSV-99',\n",
    "      'P90 HSR Distance',\n",
    "   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b92712a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique position names\n",
    "positions = df.select(\"position_grouped\").unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da8350",
   "metadata": {},
   "source": [
    "# 2 metrics\n",
    "Clustering competitions based on 2 metrics\n",
    "Competitions are clusterd together  based on there group mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b7b9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0310139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:02<00:00,  4.05it/s]\n"
     ]
    }
   ],
   "source": [
    "with xlsxwriter.Workbook(f\"./competition_clusters.xlsx\") as wb:\n",
    "    \n",
    "    # loop through the positions\n",
    "    for position in tqdm(positions[\"position_grouped\"]): \n",
    "\n",
    "        #filter on the correct position\n",
    "        pos_df = df.filter(\n",
    "            pl.col(\"position_grouped\") == position\n",
    "        ).drop(\n",
    "            \"position_grouped\"\n",
    "        ).group_by(\n",
    "            \"competition_region_division\"\n",
    "        ).agg([\n",
    "            pl.col(\"PSV-99\").mean().alias(\"PSV-99 mean\"),\n",
    "            pl.col(\"P90 HSR Distance\").mean().alias(\"P90 HSR Distance mean\"),\n",
    "        ])\n",
    "\n",
    "        # create the features --> drop competitions: not numerical & not needed to create clusters\n",
    "        features = pos_df.drop(\"competition_region_division\")\n",
    "        \n",
    "        # scale the features to avoid influence of metric size\n",
    "        scaled_features = scaler.fit_transform(features)\n",
    "        scaled_features_df = pl.DataFrame(scaled_features, schema=features.columns)\n",
    "        \n",
    "        # initialize optimal number of clusters (lowest possible)\n",
    "        best_k = 0\n",
    "        # initialize silhoutte score (lowest possible)\n",
    "        best_score = -1\n",
    "\n",
    "        cluster_models = {}\n",
    "        # calculate silhouette score for different cluster numbers\n",
    "        # save best scoring cluster\n",
    "        for k in range(2, 6):\n",
    "            cluster_models[k] = {}  # Initialize the dictionary for each k\n",
    "            cluster_models[k]['model'] = KMeans(n_clusters=k, random_state=42,init='k-means++', n_init=50, max_iter=1000)\n",
    "            cluster_models[k]['labels'] = cluster_models[k]['model'].fit_predict(scaled_features)\n",
    "            cluster_models[k]['score'] = silhouette_score(scaled_features, cluster_models[k]['labels'])\n",
    "           \n",
    "            \n",
    "        for key in cluster_models.keys():\n",
    "            if cluster_models[key]['score'] > best_score:\n",
    "                best_score = cluster_models[key]['score']\n",
    "                best_k = key \n",
    "       \n",
    "        final_df = pos_df.with_columns(pl.Series(\"Clusters\", cluster_models[best_k]['labels']))\n",
    "        \n",
    "        final_df.write_excel(\n",
    "            workbook = wb,\n",
    "            worksheet = position,\n",
    "            autofit = True,\n",
    "            float_precision = 3,\n",
    "            freeze_panes = (1,0),\n",
    "            header_format = {\"bold\": True}\n",
    "        )\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f56d38b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "club_brugge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
